#!/usr/bin/env pythonimport argparseimport sysimport osimport subprocessimport shutil#######################################################################################################################################################################def calculate_genome_length(fasta_file):    genome_name = ''    genome_length = 0    with open(fasta_file, 'r') as fasta:        for line in fasta:            if line.startswith('>'):                genome_name = line.strip().lstrip('>')            else:                genome_length += len(line.strip())    return genome_name, genome_length#######################################################################################################################################################################def find_and_record_fully_covering_reads(sam_file, trim_length, spanning_length, fasta_file, output_dir_prefix, read_number):    '''截取的序列，第一次mapping实验后，检索符合要求的reads，形成报告'''    if not os.path.isfile(sam_file):    #实际上sam_file肯定会存在        print(f"Number of reads mapping onto {fasta_file} is 0.")        return False    # Check if SAM file has only headers or is empty    with open(sam_file, 'r', encoding='utf-8') as file:        if all(line.startswith('@') for line in file) or os.path.getsize(sam_file) == 0:            print(f"No reads map onto the trimmed reference sequence {fasta_file}.")               return False    trim_length = int(trim_length)    spanning_length = int(spanning_length)    genome_name, genome_length = calculate_genome_length(fasta_file)     # 计算参考序列的长度和名称    fully_covering_reads = []          # 存储符合条件的reads名称    fully_covering_sam_lines = []      # 存储符合条件的SAM行    min_distances = []                 # 存储每个符合条件的read到重复序列边界的最小距离    with open(sam_file, 'r', encoding='utf-8') as sam:        for line in sam:            if line.startswith('@'):                fully_covering_sam_lines.append(line.strip())                continue            fields = line.strip().split('\t')            start_pos = int(fields[3])            cigar = fields[5]            first_M_pos, last_M_pos, M_count_before_trim, M_count_after_trim = get_M_positions(cigar, start_pos, trim_length, genome_length)            # 对spanning_length符合要求的，进行信息的采集            if (first_M_pos <= trim_length - spanning_length and M_count_before_trim >= spanning_length) and \               (last_M_pos >= genome_length - trim_length + spanning_length and M_count_after_trim >= spanning_length):                fully_covering_reads.append(fields[0])               # 添加reads名称                fully_covering_sam_lines.append(line.strip())        # 添加SAM行                                # 计算first_M_pos与重复序列起点间的距离以及last_M_pos与重复序列终点间的距离的最小值                distance_to_start = trim_length - first_M_pos                distance_to_end = last_M_pos - (genome_length - trim_length)                min_distance = min(distance_to_start, distance_to_end)                min_distances.append(min_distance)    fully_covering_reads_count = len(fully_covering_reads)        # 统计符合条件的reads数量    output_sam_file = os.path.join(output_dir_prefix, "repeat-spanning_read.sam")        # 输出筛选后的SAM文件    with open(output_sam_file, "w", encoding='utf-8') as output_file:        for sam_line in fully_covering_sam_lines:            output_file.write(f"{sam_line}\n")    # 输出统计信息文件    with open(os.path.join(output_dir_prefix, "repeat-spanning_read.txt"), "w", encoding='utf-8') as summary_file:        summary_file.write(f"Trimmed seq name:\t{genome_name}\n")        summary_file.write(f"Trimmed seq length:\t{genome_length}\n")        summary_file.write(f"Spanning read number:\t{fully_covering_reads_count}\n")        for i, read_name in enumerate(fully_covering_reads):            summary_file.write(f"{read_name}:\t{min_distances[i]}\n")    #Delete the out.sam by mapping software.    os.remove(sam_file) if os.path.isfile(sam_file) else None    # Check if spanning_reads.sam file contains only headers    if fully_covering_reads_count < int(read_number):        print(f"Number of reads spanning {genome_name} is insufficient: {fully_covering_reads_count}.", end='')        return False    else:        print(f"Number of reads spanning {genome_name} is sufficient: {fully_covering_reads_count}.", end='')        return True#######################################################################################################################################################################def get_M_positions(cigar, start_pos, trim_length, genome_length):    """解析 CIGAR 字符串，返回第一个和最后一个 M 的位置，以及特定区间内 M 的数量"""    num = ''    first_M_pos = 0    current_pos = start_pos    last_M_pos = 0    M_count_before_trim = 0  # 计算 first_M_pos 与 trim_length 之间的 'M'    M_count_after_trim = 0   # 计算 last_M_pos 与 genome_length - trim_length 之间的 'M'    for char in cigar:        if char.isdigit():            num += char        else:            if char in 'MDN=X':  # 这些操作会改变位置                if num:                    length = int(num)                    if char == 'M':                        if first_M_pos == 0:  # 找到第一个 M                            first_M_pos = current_pos                            M_count_before_trim += max(0, min(length, trim_length - current_pos))                        else:                            # 计算在 trim_length 和 genome_length - trim_length 之间的 'M'                            if current_pos < trim_length:                                M_count_before_trim += max(0, min(length, trim_length - current_pos))                            if current_pos + length > genome_length - trim_length:                                M_count_after_trim += max(0, min(length, current_pos + length - (genome_length - trim_length)))                        last_M_pos = current_pos + length - 1  # 更新最后一个 M 的位置                    current_pos += length            num = ''    return first_M_pos, last_M_pos, M_count_before_trim, M_count_after_trim#######################################################################################################################################################################def convert_sort_index_bam(sam_file, output_prefix, fasta_file):    '''检索符合要求的reads，若存在符合要求的reads，进行覆盖度计算和映射结果的可视化'''        # Check if SAM file exist!    if not os.path.isfile(sam_file):    #实际上sam_file肯定会存在        print(f"Number of reads mapping to {fasta_file} is 0. ")        return            # Check if SAM file has only headers or is empty    with open(sam_file, 'r', encoding='utf-8') as file:        if all(line.startswith('@') for line in file) or os.path.getsize(sam_file) == 0:            print(f"\nInsufficient reads span the repeat unit of {fasta_file}.")            return                # 确保 output_prefix 是目录路径    output_dir = os.path.dirname(output_prefix)    if output_dir and not os.path.isdir(output_dir):        os.makedirs(output_dir)    # 构造完整的文件路径    bam_file = os.path.join(output_prefix, "spanning_reads.bam")    sorted_bam_file = os.path.join(output_prefix, "spanning_reads_sorted.bam")    coverage_file = os.path.join(output_prefix, "coverage.txt")    # Convert SAM to BAM    subprocess.run(["samtools", "view", "-bS", sam_file, "-o", bam_file])    # Sort BAM file    subprocess.run(["samtools", "sort", bam_file, "-o", sorted_bam_file])    # Index BAM file    subprocess.run(["samtools", "index", sorted_bam_file])    # Calculate coverage and write to file    with open(coverage_file, "w", encoding='utf-8') as cf:        subprocess.run(["samtools", "depth", sorted_bam_file], stdout=cf)    # Remove intermediate BAM file    if os.path.isfile(bam_file):        os.remove(bam_file)            # Remove intermediate SAM file, containing spanning reads.    if os.path.isfile(sam_file):        os.remove(sam_file)    # 获取当前脚本的目录路径    current_dir = os.path.dirname(os.path.realpath(__file__))    plot_script = os.path.join(current_dir, "plot.py")  # 构建 plot.py 的完整路径    # 调用 plot.py 子程序    output_file = os.path.join(output_prefix, "spanning_reads_sequencing_depth")    subprocess.run(['python', plot_script, coverage_file, output_file, 'pdf'])       #将输出的图片文件固定为pdf格式    #######################################################################################################################################################################def parse_meaningless_results(value):    if isinstance(value, str):        normalized_value = value.strip().upper()        if normalized_value == "D":            return True        elif normalized_value == "K":            return False        else:            raise ValueError("Invalid parameter 'meaningless results'. It must be 'D' or 'K'.")    else:        raise TypeError("Input must be a string.")#####################################################################################################################################################################def main():    parser = argparse.ArgumentParser(description="Find and Record reads spanning repeat in a SAM file, supporting genome recombination.")    parser.add_argument("-s", "--sam_file", help="Input SAM file path.")    parser.add_argument("-i", "--fasta_file", help="Reference genome FASTA file path.")    parser.add_argument("-o", "--output_dir_prefix", help="Prefix for the output directory and files.")    parser.add_argument("-cl", "--spanning_length", help="The length of a read that spanning repeats.")    parser.add_argument("-tl", "--trim_length", help="The length of the intercepted sequence beyond the repeat.")    parser.add_argument("-rn", "--read_number", type=int, help="Number of reads spanning repeats.")    parser.add_argument("-mr", "--meaningless_results", help="Remove the mapping results of those trimmed reference sequences with no repeat-spanning READs.")    parser.add_argument("-a", "--alignment", choices=["minimap2", "bwa", "blast"], default="minimap2", help="Specifies the alignment software to be used. Default is minimap2.")        try:        args = parser.parse_args()    except argparse.ArgumentError as e:        parser.print_help()        sys.exit(1)            # Access the parsed arguments    sam_file = args.sam_file    fasta_file = args.fasta_file    output_dir_prefix = args.output_dir_prefix    spanning_length = args.spanning_length    trim_length = args.trim_length    read_number = args.read_number    meaningless_results = args.meaningless_results    alignment = args.alignment    # Check for missing required arguments    if not all([sam_file, fasta_file, output_dir_prefix, trim_length, spanning_length]):        parser.print_help()        sys.exit(1)            ################################################################################    # 此处考虑对结果的再次过滤，当要求删除中间结果的时候，则按照用户的设置，来设置read_number和spanning_length    # 重新过滤的时候，read_number和spanning_length的值就不能小于一开始设置的值。    # 如果用户不要求删除中间结果的时候，read_number和spanning_length 将均设置为1.    # 用户重新过滤的时候，read_number和spanning_length的值只需要 >= 1 即可。不受初始设置值的影响。    meaningless_logic = parse_meaningless_results(meaningless_results)    if not meaningless_logic:        read_number = 1        spanning_length = 1            # 检查输出目录是否存在    if not os.path.isdir(output_dir_prefix):        # 创建新的输出目录        os.makedirs(output_dir_prefix)    if alignment == "minimap2" or alignment == "bwa":        if not os.path.isfile(args.sam_file) or os.path.getsize(args.sam_file) == 0:  #基因组的组装结果没有reads能够映射上来。            print(f"Insufficient repeat-spanning reads found in the trimmed sequence {fasta_file}.")            return            logic_result = find_and_record_fully_covering_reads(args.sam_file, trim_length, spanning_length, args.fasta_file, output_dir_prefix, read_number)            if logic_result:            convert_sort_index_bam(os.path.join(output_dir_prefix, "repeat-spanning_read.sam"), args.output_dir_prefix, args.fasta_file)  # 做mapping和绘制测序深度图片，为汇总之后的步骤    if alignment == "blast":        if not os.path.isfile(args.sam_file) or os.path.getsize(args.sam_file) == 0:  #基因组的组装结果没有reads能够映射上来。            print(f"Insufficient repeat-spanning reads found in the trimmed reference sequence {fasta_file}.")            return            logic_result = find_and_record_fully_covering_reads(args.sam_file, trim_length, spanning_length, args.fasta_file, output_dir_prefix, read_number)            if logic_result:            convert_sort_index_bam(os.path.join(output_dir_prefix, "repeat-spanning_read.sam"), args.output_dir_prefix, args.fasta_file)  # 做mapping和绘制测序深度图片，为汇总之后的步骤    # 此处是一定会删除一些中间结果的，要么按照用户设置的read_number和spanning_length来删除，要么按照read_number = 1 和spanning_length = 1 来删除。    if not logic_result:     # and meaningless_logic:        shutil.rmtree(os.path.join(output_dir_prefix))    #删除截取的文件 fasta_file    if os.path.isfile(fasta_file):        os.remove(fasta_file)#####################################################################################################################################################################if __name__ == "__main__":    main()