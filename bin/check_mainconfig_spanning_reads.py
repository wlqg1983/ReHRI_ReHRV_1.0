#!/usr/bin/env pythonimport argparseimport sys, osimport subprocess#######################################################################################################################################################################def calculate_genome_length(fasta_file):    genome_name = ''    genome_length = 0    with open(fasta_file, 'r', encoding='utf-8') as fasta:        for line in fasta:            if line.startswith('>'):                genome_name = line.strip().lstrip('>')            else:                genome_length += len(line.strip())    return genome_name, genome_length    #######################################################################################################################################################################def parse_meaningless_results(value):    if isinstance(value, str):        normalized_value = value.strip().upper()        if normalized_value == "D":            return True        elif normalized_value == "K":            return False        else:            raise ValueError("Invalid parameter 'meaningless results'. It must be 'D' or 'K'.")    else:        raise TypeError("Input must be a string.")        #######################################################################################################################################################################def find_and_record_fully_covering_reads(sam_file, trim_length, spanning_length, fasta_file, output_dir_prefix):     '''截取的序列，第一次mapping实验后，检索符合要求的reads'''       if not os.path.isfile(sam_file):    #实际上sam_file肯定会存在        print(f"Number of reads mapping to {fasta_file} is 0. ")        return        # Check if SAM file has only headers or is empty    with open(sam_file, 'r') as file:        if all(line.startswith('@') for line in file) or os.path.getsize(sam_file) == 0:            print(f"No any reads map onto the trimmed sequence {fasta_file}.")            return        trim_length = int(trim_length)    spanning_length = int(spanning_length)    genome_name, genome_length = calculate_genome_length(fasta_file)    fully_covering_reads = []    fully_covering_sam_lines = []    min_distances = []  # 用于存储每个read的最小距离    with open(sam_file, 'r', encoding='utf-8') as sam:        for line in sam:            if line.startswith('@'):                fully_covering_sam_lines.append(line.strip())                continue            fields = line.strip().split('\t')            start_pos = int(fields[3])            cigar = fields[5]            first_M_pos, last_M_pos, M_count_before_trim, M_count_after_trim = get_M_positions(cigar, start_pos, trim_length, genome_length)            # 对spanning_length符合要求的，进行信息的采集            if (first_M_pos <= trim_length - spanning_length and M_count_before_trim >= spanning_length) and \               (last_M_pos >= genome_length - trim_length + spanning_length and M_count_after_trim >= spanning_length):            #if (first_M_pos <= trim_length - spanning_length) and (last_M_pos >= genome_length - trim_length + spanning_length):                fully_covering_reads.append(fields[0])                fully_covering_sam_lines.append(line.strip())                                # 计算first_M_pos与重复序列起点间的距离以及last_M_pos与重复序列终点间的距离的最小值                distance_to_start = trim_length - first_M_pos                distance_to_end = last_M_pos - (genome_length - trim_length)                min_distance = min(distance_to_start, distance_to_end)                min_distances.append(min_distance)                    fully_covering_reads_count = len(fully_covering_reads)    output_sam_file = os.path.join(output_dir_prefix, "repeat-spanning_read.sam")    with open(output_sam_file, "w", encoding='utf-8') as output_file:        for sam_line in fully_covering_sam_lines:            output_file.write(f"{sam_line}\n")    with open(os.path.join(output_dir_prefix, "repeat-spanning_read.txt"), "w", encoding='utf-8') as summary_file:        summary_file.write(f"Trimmed_seq_name:\t{genome_name}\n")        summary_file.write(f"Trimmed_seq_length:\t{genome_length}\n")        summary_file.write(f"Spanning_read_number:\t{fully_covering_reads_count}\n")        for i, read_name in enumerate(fully_covering_reads):            summary_file.write(f"{read_name}:\t{min_distances[i]}\n")    #Delete the out.sam by mapping software.    os.remove(sam_file)  if os.path.isfile(sam_file) else None    print(f"Number of reads spanning {genome_name} is: {fully_covering_reads_count}", end='')    #######################################################################################################################################################################def get_M_positions(cigar, start_pos, trim_length, genome_length):    """解析 CIGAR 字符串，返回第一个和最后一个 M 的位置，以及特定区间内 M 的数量"""    num = ''    first_M_pos = 0    current_pos = start_pos    last_M_pos = 0    M_count_before_trim = 0  # 计算 first_M_pos 与 trim_length 之间的 'M'    M_count_after_trim = 0   # 计算 last_M_pos 与 genome_length - trim_length 之间的 'M'    for char in cigar:        if char.isdigit():            num += char        else:            if char in 'MDN=X':  # 这些操作会改变位置                if num:                    length = int(num)                    if char == 'M':                        if first_M_pos == 0:  # 找到第一个 M                            first_M_pos = current_pos                            M_count_before_trim += max(0, min(length, trim_length - current_pos))                        else:                            # 计算在 trim_length 和 genome_length - trim_length 之间的 'M'                            if current_pos < trim_length:                                M_count_before_trim += max(0, min(length, trim_length - current_pos))                            if current_pos + length > genome_length - trim_length:                                M_count_after_trim += max(0, min(length, current_pos + length - (genome_length - trim_length)))                        last_M_pos = current_pos + length - 1  # 更新最后一个 M 的位置                    current_pos += length            num = ''    return first_M_pos, last_M_pos, M_count_before_trim, M_count_after_trim#######################################################################################################################################################################def convert_sort_index_bam(sam_file, fasta_file, output_prefix):    '''检索符合要求的reads，若存在符合要求的reads，进行覆盖度计算和映射结果的可视化'''        # Check if SAM file exist!    if not os.path.isfile(sam_file):    #实际上sam_file肯定会存在        print(f"Number of reads spanning {fasta_file} is 0.")        return            # Check if SAM file has only headers or is empty    with open(sam_file, 'r', encoding='utf-8') as file:        if all(line.startswith('@') for line in file) or os.path.getsize(sam_file) == 0:            print(f"\nNo reads span the repeat unit of {fasta_file}.")            return                # 确保 output_prefix 是目录路径    output_dir = os.path.dirname(output_prefix)    if output_dir and not os.path.isdir(output_dir):        os.makedirs(output_dir)    # 构造完整的文件路径    bam_file = os.path.join(output_prefix, "spanning_reads.bam")    sorted_bam_file = os.path.join(output_prefix, "spanning_reads_sorted.bam")    coverage_file = os.path.join(output_prefix, "coverage.txt")    # Convert SAM to BAM    subprocess.run(["samtools", "view", "-bS", sam_file, "-o", bam_file])    # Sort BAM file    subprocess.run(["samtools", "sort", bam_file, "-o", sorted_bam_file])    # Index BAM file    subprocess.run(["samtools", "index", sorted_bam_file])    # Calculate coverage and write to file    with open(coverage_file, "w", encoding='utf-8') as cf:        subprocess.run(["samtools", "depth", sorted_bam_file], stdout=cf)    # Remove intermediate BAM file    if os.path.isfile(bam_file):        os.remove(bam_file)    # Remove intermediate SAM file, containing spanning reads.    # 此处可不再删除 筛选后的 sam 文件，为后面重新过滤 reads 做准备    if os.path.isfile(sam_file):        os.remove(sam_file)    # 获取当前脚本的目录路径    current_dir = os.path.dirname(os.path.realpath(__file__))    plot_script = os.path.join(current_dir, "plot.py")  # 构建 plot.py 的完整路径    # 调用 plot.py 子程序    output_file = os.path.join(output_prefix, "spanning_reads_sequencing_depth")    subprocess.run(['python', plot_script, coverage_file, output_file, 'pdf'])       #将输出的图片文件固定为pdf格式    #######################################################################################################################################################################def main():    parser = argparse.ArgumentParser(description="Find and Record reads spanning repeat in a SAM file, supporting genome recombination.")    parser.add_argument("-s", "--sam_file", help="Input SAM file path")    parser.add_argument("-i", "--fasta_file", help="Reference genome FASTA file path")    parser.add_argument("-o", "--output_dir_prefix", help="Prefix for the output directory and files.")    parser.add_argument("-cl", "--spanning_length", help="The length of a read that spanning repeats.")    parser.add_argument("-tl", "--trim_length", help="The length of the intercepted sequence beyond the repeat.")    parser.add_argument("-mr", "--meaningless_results", help="Remove the mapping results of those trimmed sequences with no repeat-spanning READs.")    parser.add_argument("-a", "--alignment", choices=["minimap2", "bwa", "blast"], default="minimap2", help="Specifies the alignment software to be used. Default is minimap2.")        try:        args = parser.parse_args()    except argparse.ArgumentError as e:        parser.print_help()        sys.exit(1)            # Access the parsed arguments    sam_file = args.sam_file    fasta_file = args.fasta_file    output_dir_prefix = args.output_dir_prefix    spanning_length = args.spanning_length    trim_length = args.trim_length    alignment = args.alignment    meaningless_results = args.meaningless_results    # Check for missing required arguments    if not all([sam_file, fasta_file, output_dir_prefix, trim_length, spanning_length]):        parser.print_help()        sys.exit(1)    meaningless_logic = parse_meaningless_results(meaningless_results)    if not meaningless_logic:       # 在保留中间结果的时候，mainconfiguration 来的TSS，spanning_length 设置为固定值 1。        spanning_length = 1         # 为后面进行再过滤做准备，spanning read number 在 mainconfiguration 不考虑            # 检查输出目录是否存在     if not os.path.isdir(output_dir_prefix):        # 创建新的输出目录        os.makedirs(output_dir_prefix)    if not os.path.isfile(args.sam_file) or os.path.getsize(args.sam_file) == 0: #基因组的组装结果没有reads能够映射上来。        print(f"Sequencing depth is too low and there is a gap here {fasta_file} in the mitogenome.")        return        if alignment == "minimap2" or alignment == "bwa":        # 汇总第一次mapping结果，查找spanning reads        # mainconfig中无论spanning read数量多少，均汇总其数量，最后的结果中会标记mainconfig中spanning reads过少的情况。只要为0，不再汇总。        find_and_record_fully_covering_reads(args.sam_file, trim_length, spanning_length, args.fasta_file, output_dir_prefix)    if alignment == "blast":        find_and_record_fully_covering_reads(args.sam_file, trim_length, spanning_length, args.fasta_file, output_dir_prefix)        convert_sort_index_bam(os.path.join(output_dir_prefix, "repeat-spanning_read.sam"), fasta_file, args.output_dir_prefix)  # 做mapping和绘制测序深度图片，为汇总之后的步骤        #删除截取的文件 fasta_file    if os.path.isfile(fasta_file):        os.remove(fasta_file)    #######################################################################################################################################################################if __name__ == "__main__":    main()